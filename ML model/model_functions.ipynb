{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b9927db-d8e7-4c15-ac50-01695bf31b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import mysql.connector\n",
    "from sklearn.svm import SVC\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from mysql.connector import Error\n",
    "from sklearn.utils import shuffle\n",
    "from urllib.parse import quote_plus\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d72bf8a9-0fe8-4c56-a613-9a80ebcf0ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of connection and engine\n",
    "def connection(host_name, user_name, user_password, dbname):\n",
    "    connection = None\n",
    "    user_password = quote_plus(user_password)\n",
    "    try:\n",
    "        connection = mysql.connector.connect(host=host_name, user=user_name, passwd = user_password, database  = dbname)\n",
    "    except Error as e:\n",
    "        print(f\"The error {e} has occured\")\n",
    "    return connection\n",
    "\n",
    "def engine(host_name, user_name, user_password, dbname, port):\n",
    "    engine = create_engine(f'mysql+pymysql://{user_name}:{user_password}@{host_name}:{port}/{dbname}')\n",
    "    return engine\n",
    "\n",
    "# extraction of transformed bank data\n",
    "def extract_bank():\n",
    "    conn= connection(\"localhost\", \"root\", \"Layaldbroot1997\", \"fraudulent_activities\")\n",
    "    cursor=conn.cursor()\n",
    "    query=\"SELECT * FROM fraudulent_activities.bank\"\n",
    "    cursor.execute(query)\n",
    "    data=cursor.fetchall()\n",
    "    column_names=[i[0] for i in cursor.description]\n",
    "    df=pd.DataFrame(data, columns=column_names)\n",
    "    return df\n",
    "\n",
    "# extraction of transformed credit card data\n",
    "def extract_credit_card():\n",
    "    conn= connection(\"localhost\", \"root\", \"Layaldbroot1997\", \"fraudulent_activities\")\n",
    "    cursor=conn.cursor()\n",
    "    query=\"SELECT * FROM fraudulent_activities.credit_card\"\n",
    "    cursor.execute(query)\n",
    "    data=cursor.fetchall()\n",
    "    column_names=[i[0] for i in cursor.description]\n",
    "    df=pd.DataFrame(data, columns=column_names)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8de69896-4bda-44ee-b6c1-c7e05be483cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data():\n",
    "    dfb = extract_bank()\n",
    "    dfcc = extract_credit_card()\n",
    "    \n",
    "    # drop unnecessary columns from bank data\n",
    "    cols = ['TransactionID', 'cc_num', 'Location', 'CustomerID', 'gender', 'Address', 'trans_timestamp','Day_of_Week', 'c_zip', 'm_zip']\n",
    "    new_dfb = dfb.drop(cols, axis = 1)\n",
    "\n",
    "    # drop unnecessary columns from credit card data\n",
    "    ccols = ['trans_date_trans_time', 'cc_num', 'first', 'last', 'gender', 'lat', 'long', 'city_pop', 'trans_num', 'unix_time', 'merch_lat', 'merch_long', 'Day_of_Week', 'zip', 'm_zip']\n",
    "    new_dfcc = dfcc.drop(ccols, axis = 1)\n",
    "\n",
    "    # renaming columns to join the 2 dataframes\n",
    "    new_dfb = new_dfb.rename(columns = {\n",
    "        'Category':'category',\n",
    "        'TransactionAmount':'amt',\n",
    "        'MerchantName': 'merchant',\n",
    "        'CustomerName': 'customer_name',\n",
    "        'FraudIndicator': 'is_fraud',\n",
    "        'c_street': 'street',\n",
    "        'c_city':'city',\n",
    "        'c_state': 'state',\n",
    "        'c_zip': 'zip'\n",
    "    })\n",
    "    \n",
    "    # ordered the columns, concatenated the 2 dataframes and shuffled the records\n",
    "    new_dfb = new_dfb[new_dfcc.columns]\n",
    "    df = pd.concat([new_dfb, new_dfcc])\n",
    "    df = shuffle(df).reset_index(drop=True)\n",
    "    df['dob'] = pd.to_datetime(df['dob'])\n",
    "    return df\n",
    "\n",
    "def bin_data(df):\n",
    "    # calculate the age at the time of the transaction\n",
    "    df['age'] = df.apply(lambda row: row['trans_year']-row['dob'].year-((row['trans_month'], row['trans_day'])<(row['dob'].month, row['dob'].day)), axis=1)\n",
    "    \n",
    "    # binning age\n",
    "    age_bins = [10, 19, 29, 39, 49, 59, 69, 79, float('inf')]\n",
    "    age_labels = ['10-19', '20-29', '30-39', '40-49', '50-59', '60-69', '70-79', '80+']\n",
    "    df['age_category'] = pd.cut(df['age'], bins=age_bins, labels=age_labels, right=True)\n",
    "\n",
    "    # binning amount\n",
    "    amt_bins = [1, 500, 1000, 2000, 3000, 4000, 5000]\n",
    "    amt_labels = ['1-500', '501-1000', '1001-2000', '2001-3000', '3001-4000', '4001-5000']\n",
    "    df['amt_category'] = pd.cut(df['amt'], bins=amt_bins, labels=amt_labels, right=True, include_lowest=True)\n",
    "\n",
    "    # drop binned attributes\n",
    "    df = df.drop(['age','dob', 'amt'], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b758cad-14a5-4573-a68a-7a15fd2fe7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(df):\n",
    "    # encode categorical attributes\n",
    "    label_encoder = LabelEncoder()\n",
    "    df['merchant'] = label_encoder.fit_transform(df['merchant'])\n",
    "    df['category'] = label_encoder.fit_transform(df['category'])\n",
    "    df['street'] = label_encoder.fit_transform(df['street'])\n",
    "    df['city'] = label_encoder.fit_transform(df['city'])\n",
    "    df['state'] = label_encoder.fit_transform(df['state'])\n",
    "    df['job'] = label_encoder.fit_transform(df['job'])\n",
    "    df['customer_name'] = label_encoder.fit_transform(df['customer_name'])\n",
    "    df['m_street'] = label_encoder.fit_transform(df['m_street'])\n",
    "    df['m_city'] = label_encoder.fit_transform(df['m_city'])\n",
    "    df['m_state'] = label_encoder.fit_transform(df['m_state'])\n",
    "    df['age_category'] = label_encoder.fit_transform(df['age_category'])\n",
    "    df['amt_category'] = label_encoder.fit_transform(df['amt_category'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7d88241-ed77-46af-b24a-5c9627baf729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification_models():\n",
    "    # get the data\n",
    "    df = process_data()\n",
    "\n",
    "    # binning data\n",
    "    df = bin_data(df)\n",
    "\n",
    "    # encode categorical attributes\n",
    "    df = encode_data(df)\n",
    "    \n",
    "    # split features from target labels\n",
    "    x = df.drop(['is_fraud'], axis=1)\n",
    "    y = df['is_fraud']\n",
    "    # split the data into training and testing sets and scale it\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "    \n",
    "    # dictionary of classification models\n",
    "    models = {\n",
    "        \"Decision Tree Classifier\": DecisionTreeClassifier(),\n",
    "        \"Logistic regression classifier\": LogisticRegression(solver='liblinear',max_iter=500),\n",
    "        \"Random Forest Classifier\": RandomForestClassifier(),\n",
    "        \"Support Vector Machine (SVM)\": SVC(),\n",
    "        \"K-Nearest Neighbors (KNN)\": KNeighborsClassifier(),\n",
    "        \"Gradient Boosting Classifier\": GradientBoostingClassifier()\n",
    "    }\n",
    "    results = {}\n",
    "    for model_name, model in models.items():\n",
    "        # fit modeel to data\n",
    "        model.fit(x_train_scaled, y_train)\n",
    "        \n",
    "        # predict using trained model\n",
    "        y_pred = model.predict(x_test_scaled)\n",
    "        \n",
    "        # calculate the metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_pred)\n",
    "        results[model_name] = {\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1 Score\": f1,\n",
    "            \"ROC AUC (Receiver Operating Characteristic - Area Under the Curve)\": roc_auc\n",
    "        }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc2338d6-76ba-41bd-8d5a-fa9172b7c37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model_tuning_and_evaluation():\n",
    "    # get the data\n",
    "    df = process_data()\n",
    "\n",
    "    # binning data\n",
    "    df = bin_data(df)\n",
    "\n",
    "    # encode categorical attributes\n",
    "    df = encode_data(df)\n",
    "    \n",
    "    # split features from target labels\n",
    "    x = df.drop(['is_fraud'], axis=1)\n",
    "    y = df['is_fraud']\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "    # the range of hyperparameters to search\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 150],  # nb of trees in the forest\n",
    "        'max_depth': [None, 10, 20, 30],  # max depth of the trees\n",
    "        'min_samples_split': [2, 5, 10],  # min  samples to split an internal node\n",
    "        'min_samples_leaf': [1, 2, 4],  # min samples to be at a leaf node\n",
    "    }\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='f1', n_jobs=-1)\n",
    "    \n",
    "    # split the data into training and testing sets and scale it\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "    \n",
    "    # Fit the grid search to the resampled data\n",
    "    grid_search.fit(x_train_scaled, y_train)\n",
    "    \n",
    "    # Get the best hyperparameters and corresponding model\n",
    "    best_params = grid_search.best_params_\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    best_model.fit(x_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions on the testing data\n",
    "    y_pred = best_model.predict(x_test_scaled)\n",
    "    \n",
    "    # Calculate and print various metrics to evaluate the best model's performance\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm_normalized = cm.astype('float') / 2000\n",
    "    \n",
    "    print(\"Best Model Evaluation Metrics:\")\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "    print(\"ROC AUC (Receiver Operating Characteristic - Area Under the Curve):\", roc_auc)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0a0017e-f894-4ab9-b2b5-daa23402704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prediction(value):\n",
    "    # get the data\n",
    "    df = process_data()\n",
    "\n",
    "    # spit features from target attribute\n",
    "    y = df['is_fraud']\n",
    "    x = df.drop(['is_fraud'], axis=1)\n",
    "\n",
    "    # add record to dataframe\n",
    "    df_value = pd.DataFrame([value])\n",
    "    new_df = pd.concat([x, df_value], ignore_index=True)\n",
    "\n",
    "    # bin data\n",
    "    new_df = bin_data(new_df)\n",
    "\n",
    "    # encode data\n",
    "    df_encoded = encode_data(new_df)\n",
    "\n",
    "    # retreive record after encoding it\n",
    "    encoded_value = df_encoded.iloc[-1:]\n",
    "    df_encoded = df_encoded.iloc[:-1]\n",
    "\n",
    "    # initialize model by optimal parameters\n",
    "    model = RandomForestClassifier(max_depth = 30, min_samples_leaf = 1, min_samples_split = 5, n_estimators = 100, random_state=42)\n",
    "    \n",
    "    # split the data into training and testing sets and scale it\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df_encoded, y, test_size=0.2, random_state=42)\n",
    "    scaler = StandardScaler()\n",
    "    x_train_scaled = scaler.fit_transform(x_train)\n",
    "    x_test_scaled = scaler.transform(x_test)\n",
    "    model.fit(x_train_scaled, y_train)\n",
    "\n",
    "    # scale encoded value to be predicted\n",
    "    encoded_value_scaled = scaler.transform(encoded_value)\n",
    "    prediction = model.predict(encoded_value_scaled)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0313ebfd-21cd-4f6b-bf2a-e0debcab9800",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
